{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMG Gesture Recognition Model\n",
    "\n",
    "This notebook creates a machine learning model to predict hand gestures from EMG (Electromyography) signals.\n",
    "\n",
    "## Dataset Overview\n",
    "- **Channels**: 3 EMG sensors (ch1, ch2, ch3)\n",
    "- **Gestures**: 12 different hand gestures\n",
    "- **Features**: Time and frequency domain features extracted from sliding windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from scipy import signal\n",
    "from scipy.stats import skew, kurtosis\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data/combined_emg_data (1).csv')\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore gesture distribution\n",
    "gesture_counts = data['gesture'].value_counts()\n",
    "print(\"Gesture distribution:\")\n",
    "print(gesture_counts)\n",
    "\n",
    "# Plot gesture distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "gesture_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Gestures in Dataset')\n",
    "plt.xlabel('Gesture')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize EMG signals for different gestures\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "gestures_to_plot = ['0-OPEN', '1-CLOSE', '2-PINCH', '3-POINT']\n",
    "\n",
    "for i, gesture in enumerate(gestures_to_plot):\n",
    "    ax = axes[i//2, i%2]\n",
    "    gesture_data = data[data['gesture'] == gesture].head(500)\n",
    "    \n",
    "    ax.plot(gesture_data['ch1'], label='Channel 1', alpha=0.7)\n",
    "    ax.plot(gesture_data['ch2'], label='Channel 2', alpha=0.7)\n",
    "    ax.plot(gesture_data['ch3'], label='Channel 3', alpha=0.7)\n",
    "    \n",
    "    ax.set_title(f'EMG Signals for {gesture}')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('EMG Amplitude')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_domain_features(signal_window):\n",
    "    \"\"\"Extract comprehensive time domain features from EMG signal window\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic statistical features\n",
    "    features['mean'] = np.mean(signal_window)\n",
    "    features['std'] = np.std(signal_window)\n",
    "    features['var'] = np.var(signal_window)\n",
    "    features['rms'] = np.sqrt(np.mean(signal_window**2))\n",
    "    features['max'] = np.max(signal_window)\n",
    "    features['min'] = np.min(signal_window)\n",
    "    features['range'] = features['max'] - features['min']\n",
    "    \n",
    "    # Advanced statistical features\n",
    "    features['skewness'] = skew(signal_window)\n",
    "    features['kurtosis'] = kurtosis(signal_window)\n",
    "    features['mad'] = np.mean(np.abs(signal_window - features['mean']))\n",
    "    \n",
    "    # Percentiles\n",
    "    features['q25'] = np.percentile(signal_window, 25)\n",
    "    features['q75'] = np.percentile(signal_window, 75)\n",
    "    features['iqr'] = features['q75'] - features['q25']\n",
    "    \n",
    "    # Zero crossing rate\n",
    "    zero_crossings = np.where(np.diff(np.signbit(signal_window - np.mean(signal_window))))[0]\n",
    "    features['zcr'] = len(zero_crossings) / len(signal_window)\n",
    "    \n",
    "    # Slope sign changes\n",
    "    diff_signal = np.diff(signal_window)\n",
    "    slope_changes = np.where(np.diff(np.signbit(diff_signal)))[0]\n",
    "    features['ssc'] = len(slope_changes) / len(signal_window)\n",
    "    \n",
    "    # Waveform length\n",
    "    features['wl'] = np.sum(np.abs(np.diff(signal_window)))\n",
    "    \n",
    "    # Average amplitude change\n",
    "    features['aac'] = np.mean(np.abs(np.diff(signal_window)))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_frequency_domain_features(signal_window, fs=1000):\n",
    "    \"\"\"Extract frequency domain features from EMG signal window\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Power Spectral Density\n",
    "    freqs, psd = signal.welch(signal_window, fs=fs, nperseg=min(256, len(signal_window)//4))\n",
    "    \n",
    "    total_power = np.sum(psd)\n",
    "    if total_power > 0:\n",
    "        # Mean and median frequency\n",
    "        features['mean_freq'] = np.sum(freqs * psd) / total_power\n",
    "        \n",
    "        cumsum_psd = np.cumsum(psd)\n",
    "        median_idx = np.where(cumsum_psd >= total_power/2)[0]\n",
    "        features['median_freq'] = freqs[median_idx[0]] if len(median_idx) > 0 else 0\n",
    "        \n",
    "        # Band power features\n",
    "        low_freq_band = (freqs >= 20) & (freqs <= 80)\n",
    "        mid_freq_band = (freqs >= 80) & (freqs <= 150)\n",
    "        high_freq_band = (freqs >= 150) & (freqs <= 250)\n",
    "        \n",
    "        features['low_band_power'] = np.sum(psd[low_freq_band]) / total_power\n",
    "        features['mid_band_power'] = np.sum(psd[mid_freq_band]) / total_power\n",
    "        features['high_band_power'] = np.sum(psd[high_freq_band]) / total_power\n",
    "        \n",
    "        # Peak frequency\n",
    "        features['peak_freq'] = freqs[np.argmax(psd)]\n",
    "    else:\n",
    "        features.update({key: 0 for key in ['mean_freq', 'median_freq', 'low_band_power', \n",
    "                                           'mid_band_power', 'high_band_power', 'peak_freq']})\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"Feature extraction functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Sliding Windows and Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(data, window_size=150, overlap=0.7):\n",
    "    \"\"\"Create sliding windows from continuous EMG data\"\"\"\n",
    "    step_size = int(window_size * (1 - overlap))\n",
    "    windows = []\n",
    "    labels = []\n",
    "    \n",
    "    emg_columns = ['ch1', 'ch2', 'ch3']\n",
    "    label_column = 'gesture'\n",
    "    \n",
    "    # Group by gesture to maintain consistency\n",
    "    for gesture in data[label_column].unique():\n",
    "        gesture_data = data[data[label_column] == gesture].reset_index(drop=True)\n",
    "        \n",
    "        for i in range(0, len(gesture_data) - window_size + 1, step_size):\n",
    "            window_data = gesture_data.iloc[i:i+window_size]\n",
    "            windows.append(window_data[emg_columns].values)\n",
    "            labels.append(gesture)\n",
    "    \n",
    "    return np.array(windows), np.array(labels)\n",
    "\n",
    "# Create windows\n",
    "print(\"Creating sliding windows...\")\n",
    "windows, labels = create_sliding_windows(data, window_size=150, overlap=0.7)\n",
    "print(f\"Created {len(windows)} windows\")\n",
    "print(f\"Window shape: {windows[0].shape}\")\n",
    "\n",
    "# Show distribution of windows per gesture\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "window_distribution = pd.DataFrame({'Gesture': unique_labels, 'Windows': counts})\n",
    "print(\"\\nWindows per gesture:\")\n",
    "print(window_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_windows(windows):\n",
    "    \"\"\"Extract comprehensive features from all windows\"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    print(\"Extracting features from windows...\")\n",
    "    for i, window in enumerate(windows):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Processing window {i}/{len(windows)}\")\n",
    "            \n",
    "        window_features = {}\n",
    "        \n",
    "        # Extract features for each EMG channel\n",
    "        for channel_idx in range(window.shape[1]):\n",
    "            channel_data = window[:, channel_idx]\n",
    "            \n",
    "            # Time domain features\n",
    "            td_features = extract_time_domain_features(channel_data)\n",
    "            for key, value in td_features.items():\n",
    "                window_features[f'ch{channel_idx+1}_{key}'] = value\n",
    "            \n",
    "            # Frequency domain features\n",
    "            fd_features = extract_frequency_domain_features(channel_data)\n",
    "            for key, value in fd_features.items():\n",
    "                window_features[f'ch{channel_idx+1}_{key}'] = value\n",
    "        \n",
    "        # Cross-channel correlation features\n",
    "        corr_12 = np.corrcoef(window[:, 0], window[:, 1])[0, 1]\n",
    "        corr_13 = np.corrcoef(window[:, 0], window[:, 2])[0, 1]\n",
    "        corr_23 = np.corrcoef(window[:, 1], window[:, 2])[0, 1]\n",
    "        \n",
    "        window_features['corr_ch1_ch2'] = corr_12 if not np.isnan(corr_12) else 0\n",
    "        window_features['corr_ch1_ch3'] = corr_13 if not np.isnan(corr_13) else 0\n",
    "        window_features['corr_ch2_ch3'] = corr_23 if not np.isnan(corr_23) else 0\n",
    "        \n",
    "        all_features.append(window_features)\n",
    "    \n",
    "    # Convert to DataFrame and then to numpy array\n",
    "    features_df = pd.DataFrame(all_features)\n",
    "    feature_names = features_df.columns.tolist()\n",
    "    \n",
    "    return features_df.values, feature_names\n",
    "\n",
    "# Extract features\n",
    "features, feature_names = extract_features_from_windows(windows)\n",
    "print(f\"\\nExtracted {features.shape[1]} features per window\")\n",
    "print(f\"Total feature matrix shape: {features.shape}\")\n",
    "\n",
    "# Handle any NaN or infinite values\n",
    "features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "print(\"Features cleaned and ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "print(f\"Label mapping:\")\n",
    "for i, gesture in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i}: {gesture}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train_scaled.shape}\")\n",
    "print(f\"Test set size: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and Compare Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to compare\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', C=10, gamma='scale', random_state=42, probability=True),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(200, 100), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    trained_models[name] = model\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Display results summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test Accuracy': [results[name]['accuracy'] for name in results.keys()],\n",
    "    'CV Mean': [results[name]['cv_mean'] for name in results.keys()],\n",
    "    'CV Std': [results[name]['cv_std'] for name in results.keys()]\n",
    "})\n",
    "\n",
    "results_df = results_df.sort_values('Test Accuracy', ascending=False)\n",
    "print(results_df)\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "print(f\"\\nBest Model: {best_model_name} with accuracy: {results_df.iloc[0]['Test Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detailed Analysis of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from best model\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "# Classification report\n",
    "print(f\"Classification Report for {best_model_name}:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, best_predictions, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=label_encoder.classes_,\n",
    "           yticklabels=label_encoder.classes_)\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (for tree-based models)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot top 20 features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=importance_df.head(20), x='importance', y='feature')\n",
    "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 10 most important features:\")\n",
    "    print(importance_df.head(10))\n",
    "else:\n",
    "    print(f\"Feature importance not available for {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and preprocessors\n",
    "model_data = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'label_encoder': label_encoder,\n",
    "    'feature_names': feature_names,\n",
    "    'model_name': best_model_name\n",
    "}\n",
    "\n",
    "model_filename = f'best_emg_gesture_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "joblib.dump(model_data, model_filename)\n",
    "print(f\"Best model saved as: {model_filename}\")\n",
    "\n",
    "# Also save a summary\n",
    "summary = {\n",
    "    'best_model': best_model_name,\n",
    "    'accuracy': results[best_model_name]['accuracy'],\n",
    "    'cv_accuracy': results[best_model_name]['cv_mean'],\n",
    "    'num_features': len(feature_names),\n",
    "    'num_gestures': len(label_encoder.classes_),\n",
    "    'gestures': list(label_encoder.classes_),\n",
    "    'window_size': 150,\n",
    "    'overlap': 0.7\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('model_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Model summary saved as: model_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gesture(emg_window, model, scaler, label_encoder, feature_names):\n",
    "    \"\"\"Predict gesture from a single EMG window\"\"\"\n",
    "    \n",
    "    # Extract features from the window\n",
    "    window_features = {}\n",
    "    \n",
    "    # Extract features for each EMG channel\n",
    "    for channel_idx in range(emg_window.shape[1]):\n",
    "        channel_data = emg_window[:, channel_idx]\n",
    "        \n",
    "        # Time domain features\n",
    "        td_features = extract_time_domain_features(channel_data)\n",
    "        for key, value in td_features.items():\n",
    "            window_features[f'ch{channel_idx+1}_{key}'] = value\n",
    "        \n",
    "        # Frequency domain features\n",
    "        fd_features = extract_frequency_domain_features(channel_data)\n",
    "        for key, value in fd_features.items():\n",
    "            window_features[f'ch{channel_idx+1}_{key}'] = value\n",
    "    \n",
    "    # Cross-channel correlation features\n",
    "    corr_12 = np.corrcoef(emg_window[:, 0], emg_window[:, 1])[0, 1]\n",
    "    corr_13 = np.corrcoef(emg_window[:, 0], emg_window[:, 2])[0, 1]\n",
    "    corr_23 = np.corrcoef(emg_window[:, 1], emg_window[:, 2])[0, 1]\n",
    "    \n",
    "    window_features['corr_ch1_ch2'] = corr_12 if not np.isnan(corr_12) else 0\n",
    "    window_features['corr_ch1_ch3'] = corr_13 if not np.isnan(corr_13) else 0\n",
    "    window_features['corr_ch2_ch3'] = corr_23 if not np.isnan(corr_23) else 0\n",
    "    \n",
    "    # Convert to array in correct order\n",
    "    features_array = np.array([window_features[name] for name in feature_names]).reshape(1, -1)\n",
    "    features_array = np.nan_to_num(features_array, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform(features_array)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(features_scaled)[0]\n",
    "    probability = model.predict_proba(features_scaled)[0]\n",
    "    \n",
    "    # Decode label\n",
    "    gesture_name = label_encoder.inverse_transform([prediction])[0]\n",
    "    confidence = np.max(probability)\n",
    "    \n",
    "    return gesture_name, confidence, probability\n",
    "\n",
    "# Test the prediction function with a sample from the test set\n",
    "test_window = windows[0]  # Use first window as example\n",
    "predicted_gesture, confidence, probabilities = predict_gesture(\n",
    "    test_window, best_model, scaler, label_encoder, feature_names\n",
    ")\n",
    "\n",
    "print(f\"Test prediction:\")\n",
    "print(f\"Predicted gesture: {predicted_gesture}\")\n",
    "print(f\"Confidence: {confidence:.4f}\")\n",
    "print(f\"Actual gesture: {labels[0]}\")\n",
    "\n",
    "# Show probability distribution\n",
    "prob_df = pd.DataFrame({\n",
    "    'Gesture': label_encoder.classes_,\n",
    "    'Probability': probabilities\n",
    "}).sort_values('Probability', ascending=False)\n",
    "\n",
    "print(\"\\nProbability distribution:\")\n",
    "print(prob_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EMG GESTURE RECOGNITION MODEL - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Dataset: {data.shape[0]} samples, {len(label_encoder.classes_)} gestures\")\n",
    "print(f\"Features: {len(feature_names)} features extracted from 3 EMG channels\")\n",
    "print(f\"Windows: {len(windows)} sliding windows (size={150}, overlap=70%)\")\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Test Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
    "print(f\"Cross-validation Accuracy: {results[best_model_name]['cv_mean']:.4f} Â± {results[best_model_name]['cv_std']:.4f}\")\n",
    "\n",
    "print(f\"\\nGestures recognized:\")\n",
    "for i, gesture in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {i}: {gesture}\")\n",
    "\n",
    "print(f\"\\nModel saved as: {model_filename}\")\n",
    "print(f\"Summary saved as: model_summary.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL READY FOR REAL-TIME GESTURE PREDICTION!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
